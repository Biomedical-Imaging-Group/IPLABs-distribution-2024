{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23195a344d8e600a2c5fcaee90c2f366",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" width=\"140px\" alt=\"EPFL_logo\">\n",
    "\n",
    "## Image Processing Laboratory Notebooks\n",
    "---\n",
    "\n",
    "This Jupyter Notebook is part of a series of computer laboratories that are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course \n",
    "[**MICRO-512 Image Processing II**](https://moodle.epfl.ch/course/view.php?id=463) taught by Prof. M. Unser and Prof. D. Van de Ville.\n",
    "\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the [Biomedical Imaging Group](http://bigwww.epfl.ch/). \n",
    "The distribution or reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL 2025.\n",
    "\n",
    "**Authors**: \n",
    "    [Pol del Aguila Pla](mailto:pol.delaguilapla@epfl.ch), \n",
    "    [Kay Lächler](mailto:kay.lachler@epfl.ch),\n",
    "    [Alejandro Noguerón Arámburu](mailto:alejandro.nogueronaramburu@epfl.ch),\n",
    "    [Kamil Seghrouchni](mailto:kamil.seghrouchni@epfl.ch), and\n",
    "    [Daniel Sage](mailto:daniel.sage@epfl.ch).\n",
    "    \n",
    "\n",
    "# Lab 4.2: Orientation\n",
    "**Released**: Thursday, February 20, 2025\n",
    "\n",
    "**Submission deadline**: Friday, February 28, 2025, before 23:59 on [Moodle](https://moodle.epfl.ch/course/view.php?id=463)\n",
    "\n",
    "**Grade weight**: Lab 4 (16 points), 7.5 % of the overall grade\n",
    "\n",
    "**Help Session**: Thursday, February 27, 2025\n",
    "\n",
    "**Related lectures**: Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results.\n",
    "\n",
    "**Student Name**: \n",
    "\n",
    "**SCIPER**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f33bf799b1c6d72b4286820b8994b161",
     "grade": true,
     "grade_id": "cell-8006fccc6af005fd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a41636467db6b4adab154ea5d0383ff3",
     "grade": false,
     "grade_id": "cell-0d10bea2e8b42856",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Orientation laboratory (13 points)\n",
    "\n",
    "In this lab, we implement the computation of the structure tensor presented in Chapter 6.2, which can be used to perform directional image analysis.\n",
    "The block diagram of the complete system is shown in the following flowchart, where $f(x,y)$ is the grayscale input image.\n",
    "\n",
    "![Drawing](images/block-diagram.png)\n",
    "\n",
    "Successively, we implement the functions\n",
    "* `structure_tensor` to generate the structure tensor matrix,\n",
    "* `orientation_features`, which implements the whole chain of calculations to generate the features needed for directional analysis, and\n",
    "* `colorize_features` to display the calculated features as a color image.\n",
    "\n",
    "Then, we use them in two applications relying on directional image analysis,\n",
    "* a method to select specific orientations, and\n",
    "* a keypoint detector (Harris corner detector). \n",
    "\n",
    "Finally, we discuss an alternative implementation of `structure_tensor`, improving over the previous version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56f058cf30a5cc6814d103bb47760c0d",
     "grade": false,
     "grade_id": "cell-5388b872e52f181d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Structure tensor (2 points)\n",
    "\n",
    "To calculate the elements $J_{xx}$, $J_{xy}$ and $J_{yy}$ of the structure tensor, we need a gradient filter and a Gaussian filter.\n",
    "For the gradient filter, we use [`scipy.ndimage.sobel`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.sobel.html) and for the Gaussian filter, we use [`scipy.ndimage.gaussian_filter`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html).\n",
    "\n",
    "**For 2 points**, implement `structure_tensor` in the cell below. It may be useful to revisit the [figure](#Orientation-laboratory-(13-points)) at the start of this notebook before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49ef14a4206cc47256357687b0b17914",
     "grade": false,
     "grade_id": "cell-b61dd0d40e75e8f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as nd\n",
    "\n",
    "\n",
    "def structure_tensor(img, sigma):\n",
    "    Jxx, Jxy, Jyy = [np.empty_like(img) for _ in range(3)]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return Jxx, Jxy, Jyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e8221d94a72e1d1ee216c3d0a6fbb435",
     "grade": false,
     "grade_id": "cell-c95fc6d29eace27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We perform a quick sanity check on a $11 \\times 11$ **impulse image** using `sigma=1`. \n",
    "You can modify the input image and the sigma value in the cell below to observe the different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "from interactive_kit import imviewer as viewer\n",
    "\n",
    "size = 11\n",
    "test_img = np.zeros((size, size))\n",
    "test_img[size//2, size//2] = 1\n",
    "\n",
    "Jxx, Jxy, Jyy = structure_tensor(test_img, sigma=1)\n",
    "view = viewer([test_img, Jxx, Jyy, Jxy], subplots=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3902758af319a2a87c40a7f11506dc7",
     "grade": false,
     "grade_id": "cell-c03ed9b69a5e4658",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Specifically, we check if $J_{xx}$ and $J_{yy}$ are non-negative and $\\pi / 2$ rotations of each other, which should be the case for the impulse image.\n",
    "Then, we check that $J_{xy}$ contains both negative and non-negative numbers, and that all elements that are either in the fifth row or the fifth column of $J_{xy}$ are zero. \n",
    "\n",
    "Because the structure tensor is a crucial part of this lab, we will also perform more sophisticated sanity checks comparing your results to our pre-computed correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as imageio\n",
    "\n",
    "corner, dendrochronology, fingerprint, harris_corner, wave_ramp = [\n",
    "    imageio.imread(f'images/{name}.tif') / 255.\n",
    "    for name in ['corner', 'dendrochronolgy', 'fingerprint', 'harris-corner', 'wave-ramp']\n",
    "]\n",
    "\n",
    "# you can change the image to any of the ones we imported: corner, dendrochronology, fingerprint, harris_corner, or wave_ramp\n",
    "image = wave_ramp\n",
    "Jxx, Jxy, Jyy = structure_tensor(image, sigma=1)\n",
    "plt.close('all')\n",
    "view = viewer([image, Jxx, Jxy, Jyy], subplots=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4059971c6bb0b1221c2bb76d7ab68beb",
     "grade": true,
     "grade_id": "cell-48dd71b424d32fe7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic sanity checks\n",
    "test_img = np.zeros((11, 11))\n",
    "test_img[5, 5] = 1\n",
    "Jxx, Jxy, Jyy = structure_tensor(test_img, sigma=1)\n",
    "\n",
    "if not (np.all(Jxx >= 0) and np.all(Jyy >= 0)): \n",
    "    print('WARNING!\\nJxx and Jyy should be non-negative')\n",
    "if not np.allclose(np.rot90(Jxx), Jyy):\n",
    "    print('WARNING!\\nJxx should be a rotation of Jyy')\n",
    "if not np.any(Jxy > 0) and np.any(Jxy < 0):\n",
    "    print('WARNING!\\nJxy should be positive and negative')\n",
    "if not np.all(abs(Jxy[5, :]) < 1e-5) and np.all(abs(Jxy[:, 5]) < 1e-5):\n",
    "    print('WARNING!\\nFifth row/col should be zero')\n",
    "\n",
    "# Comparison to pre-computed correct results\n",
    "Jxx_corr = np.array([\n",
    "    [0.004, 0.018, 0.033, 0.035, 0.033, 0.018, 0.004],\n",
    "    [0.025, 0.114, 0.209, 0.224, 0.209, 0.114, 0.025],\n",
    "    [0.077, 0.35,  0.644, 0.688, 0.644, 0.35,  0.077],\n",
    "    [0.113, 0.512, 0.942, 1.006, 0.942, 0.512, 0.113],\n",
    "    [0.077, 0.35,  0.644, 0.688, 0.644, 0.35,  0.077],\n",
    "    [0.025, 0.114, 0.209, 0.224, 0.209, 0.114, 0.025],\n",
    "    [0.004, 0.018, 0.033, 0.035, 0.033, 0.018, 0.004]\n",
    "])\n",
    "Jyy_corr = Jxx_corr.T\n",
    "Jxy_corr = np.array([\n",
    "    [ 0.003,  0.013,  0.019,  0.   , -0.019, -0.013, -0.003],\n",
    "    [ 0.013,  0.056,  0.082,  0.   , -0.082, -0.056, -0.013],\n",
    "    [ 0.019,  0.082,  0.119,  0.   , -0.119, -0.082, -0.019],\n",
    "    [ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ],\n",
    "    [-0.019, -0.082, -0.119,  0.   ,  0.119,  0.082,  0.019],\n",
    "    [-0.013, -0.056, -0.082,  0.   ,  0.082,  0.056,  0.013],\n",
    "    [-0.003, -0.013, -0.019,  0.   ,  0.019,  0.013,  0.003]\n",
    "])\n",
    "\n",
    "for yours, reference in zip([Jxx[2:9, 2:9], Jyy[2:9, 2:9], Jxy[2:9, 2:9]], [Jxx_corr, Jyy_corr, Jxy_corr]):\n",
    "    if not np.allclose(Jxx[2:9, 2:9], Jxx_corr, atol=1e-3): print('Your function does not pass the sanity check')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f0c5c7111aaaab322902370c11ee76e",
     "grade": false,
     "grade_id": "cell-03e0e8556b98e0e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can apply `structure_tensor` to any of the images (`corner`, `dendrochronology`, `fingerprint`, `harris_corner`, or `wave_ramp`) to inspect the elements of the structure tensor.\n",
    "In the cell below, you can change the argument to `structure_tensor` to any image and change `sigma` to observe the effect on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ca28e1898fa4a9d5415af79c6ea8789",
     "grade": false,
     "grade_id": "cell-61a2e3d706807da8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Orientation features\n",
    "\n",
    "With the structure tensor, we can compute features to help us understand and visualize the orientation of structures in an image.\n",
    "An easy way to think about the structure tensor is that, for each pixel location `[m,n]`, we can calculate a matrix $\\mathbf{J}$ made out of the values of $J_{xx}$, $J_{yy}$, and $J_{xy}$ at that pixel, \n",
    "\n",
    "$$\n",
    "    \\mathbf{J}[m,n] = \\left[ \\begin{array}{cc} J_{xx}[m,n] & J_{xy}[m,n] \\\\ J_{xy}[m,n] & J_{yy}[m,n]\\end{array} \\right]\\,.\n",
    "$$\n",
    "\n",
    "## Feature calculation (4 points)\n",
    "\n",
    "The following table below shows four features we will compute from the structure tensor (the indices are dropped for simplicity).\n",
    "There, $\\det$ is the determinant and $\\operatorname{tr}$ is the trace.\n",
    "\n",
    "| Feature | Relation to the structure tensor matrix $\\mathbf{J}$ |\n",
    "| :-: | :-: |\n",
    "| Orientation | $\\Theta = \\frac{1}{2}\\arctan\\left(\\frac{2J_{xy}}{J_{yy}-J_{xx}}\\right)$ |\n",
    "| Gradient Energy | $E = J_{yy}+J_{xx}$ |\n",
    "| Coherence | $C = \\frac{\\sqrt{(J_{yy}-J_{xx})^2+4J_{xy}^2}}{E}$ if $E > 0.01$ else 0 |\n",
    "| Harris Index | $H = \\det(\\mathbf{J}) - \\kappa \\operatorname{tr}(\\mathbf{J})^2\\mbox{, with }\\kappa = 0.05$ |\n",
    "\n",
    "In the cell below, complete `orientation_features`, implementing the processing chain described in the flowchart at the start of this notebook.\n",
    "Use `structure_tensor` from the previous section and implement the features (**1 point each**) specified in the table.\n",
    "Use `np.arctan2` for $\\arctan$, as it calculates the correct quadrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8e7ded936081a45fea3c6cd7b9b69542",
     "grade": false,
     "grade_id": "cell-035389b1a6a3f768",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def orientation_features(img, sigma, structure_tensor=structure_tensor):\n",
    "    orientation, energy, coherence, harris = [np.zeros_like(img) for _ in range(4)]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return orientation, energy, coherence, harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the input image and sigma, to see the result on different images: corner, dendrochronology, fingerprint, harris_corner, or wave_ramp\n",
    "input_img = wave_ramp\n",
    "sigma = 2\n",
    "images = [input_img] + list(orientation_features(input_img, sigma=sigma))\n",
    "# Display the output features\n",
    "titles = ['Input image', 'Orientation', 'Energy', 'coherence', 'Harris Index']\n",
    "plt.close('all')\n",
    "view = viewer(images, title=titles, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a3dad49656569723dfd3d30d69240fb",
     "grade": false,
     "grade_id": "cell-a73ac8dca01efbe7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a sanity check, you can run the next four cells to check that each of the output features is in the correct range when applying the function to the `wave_ramp` image using `sigma = 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56c24580baa7a3b05260c8dd8825df68",
     "grade": true,
     "grade_id": "cell-38647a28c992ce54",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "orientation, energy, coherence, harris = orientation_features(wave_ramp, sigma=2)\n",
    "if not (abs(orientation.min() + np.pi / 2) < 0.01 and abs(orientation.max() - np.pi / 2) < 0.01):\n",
    "    print('WARNING!\\nThe orientation should be in [-pi/2, pi/2].')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "822613742a91d15218f3cf525b31dbb8",
     "grade": true,
     "grade_id": "cell-20858c3ce1e3d754",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not (abs(energy.min() - 0.00023718704) < 0.01 and abs(energy.max() - 0.00044379648) < 0.01):\n",
    "    print('WARNING!\\nThe energy should be in [0.00023718704, 0.00044379648].')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a371cb7d98af94760f271ec5b4e95e42",
     "grade": true,
     "grade_id": "cell-de85aff6e335b8a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not (abs(coherence.min()) >= 0.0 and abs(coherence.max()) <= 1.0):\n",
    "    print('WARNING\\nThe coherence should be in the range [0, 1].')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "987e3310e5970312fc2e09a7141445d9",
     "grade": true,
     "grade_id": "cell-4966f03b2a2bebb9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not (abs(harris.min() + -9.831781e-09) < 0.01 and abs(harris.max() - 2.6322816e-08) < 0.01):\n",
    "    print('WARNING!\\nThe Harris index should be in [9.831781e-09, 2.6322816e-08].')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17be8174607d2063ddffc96d9be1adaf",
     "grade": false,
     "grade_id": "cell-98e9a94fd283428b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Feature visualization (2 points)\n",
    "\n",
    "Until now, we used grayscale images to visualize the orientation features, allowing only a single feature to be displayed at once.\n",
    "However, we often want to visualize several features in the same image, making the visual analysis more intuitive.\n",
    "We do this by leveraging the **hue, saturation, value (HSV)** color representation depicted below.\n",
    "We assign the orientation (which is $2\\pi$ periodic) to the hue (which is also periodic), the coherence (a value between $0$ and $1$) to the saturation, and the original image to the value, which allows us to see the objects in the image.\n",
    "\n",
    "![Drawing](images/hsv_color_representation.png)\n",
    "\n",
    "**For 2 points**, implement `colorize_features`, taking *orientation*, *coherence*, *input image*, and a *mode* (see table below) as arguments. The function should create an HSV image `hsv_image` from the orientation features, which is converted to RGB to display it with the `viewer`.\n",
    "\n",
    "The function will have two modes:\n",
    "In both modes, the orientation $o \\in [-\\pi/2, \\pi/2]$ is mapped to $[0, 1]$ via $o \\mapsto (o + \\pi/2) / \\pi$, which is put into the hue channel.\n",
    "In mode $0$, the saturation and value channels are left constant at `1`.\n",
    "In mode $1$, the coherence is put into the saturation channel, and the input image is put into the value channel.\n",
    "The coherence and the input image can be directly used without any transformation.\n",
    "See the table below for the specifications of the two modes.  \n",
    "\n",
    "| Mode | H channel | S channel | V channel |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| 0: Orientation only | orientation | 1 | 1 |\n",
    "| 1: Features on image | orientation | coherence | input image |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "38f4d87fb693116577d19c2a1fb1c368",
     "grade": false,
     "grade_id": "cell-95da8e71f5180d8f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def colorize_features(orientation, coherence, img, mode=1):\n",
    "    # Fill hsv_img[:, :, 0] to set the hue, hsv_img[:, :, 1] to set the saturation, and hsv_img[:, :, 2] to set the value\n",
    "    hsv = np.zeros((*img.shape, 3))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Convert HSV to RGB\n",
    "    return matplotlib.colors.hsv_to_rgb(hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f69e5d231f4cd967e6fcda104286d715",
     "grade": false,
     "grade_id": "cell-674dd871665d5425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now run the next two cells for a quick test on your function. As usual, remember that these tests are not definitive and that they do not guarantee the full points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bddd889efd15611881882f1a851d5889",
     "grade": true,
     "grade_id": "cell-f91804a62df5936d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "orientation = np.array([[-np.pi / 2, -np.pi / 4, 0, np.pi / 4, np.pi / 2]])\n",
    "coherence   = np.array([[0, 65, 130, 195, 255]]) / 255.\n",
    "img = np.array([[255, 195, 130, 65, 0]]) / 255.\n",
    "reference = np.array([[[1, 0, 0], [0.5, 1, 0], [0, 1, 1],[0.5,   0, 1], [1,   0,   0]]])\n",
    "\n",
    "colorized_img = colorize_features(orientation, coherence, img, mode=0)\n",
    "if not np.allclose(colorized_img, reference):\n",
    "    print('WARNING!\\nYour colorization function is not yet correct for mode 0. Check the comparison below:')\n",
    "    viewer([ours, reference], title=['Your output', 'Expected output'], subplots=(1,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f386f1fde38a815b81de7559ecb5326b",
     "grade": true,
     "grade_id": "cell-3c0ee73d8a36cbb7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "orientation = np.array([[-np.pi / 2, -np.pi / 4, 0, np.pi / 4, np.pi / 2]])\n",
    "coherence   = np.array([[0, 65, 130, 195, 255]]) / 255.\n",
    "img = np.array([[255, 195, 130, 65, 0]]) / 255.\n",
    "reference = np.array([[[1.,         1.,         1.],\n",
    "  [0.66724337, 0.76470588, 0.56978085],\n",
    "  [0.24990388, 0.50980392, 0.50980392],\n",
    "  [0.15743945, 0.05997693, 0.25490196],\n",
    "  [0.,         0.,         0.,        ]]])\n",
    "\n",
    "colorized_img = colorize_features(orientation, coherence, img, mode=1)\n",
    "if not np.allclose(colorized_img, reference):\n",
    "    print('WARNING!\\nYour colorization function is not yet correct for mode 1. Check the comparison below:')\n",
    "    viewer([ours, reference], title=['Your output', 'Expected output'], subplots=(1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d6b3afa21d1934755b9c2bbe0301c7ce",
     "grade": false,
     "grade_id": "cell-fddbf52cab001282",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below we visualize the effect of `colorize_features` function on different images. \n",
    "Clicking on `Extra Widgets` reveals the interface to change the mode and sigma, and to apply the colorization by clicking on `Apply Colorization`.\n",
    "Cycle through the different images by clicking on `Next` and `Prev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b79e85e3ea80ab9d69c2b5179e681fe",
     "grade": false,
     "grade_id": "cell-4babc8c2b2129b2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "mode_dropdown = widgets.Dropdown(options=['0: Orientation only', '1: Features on image'], value='1: Features on image', description='Mode:', disabled=False)\n",
    "mode_dictionary = {'0: Orientation only': 0, '1: Features on image': 1}\n",
    "sigma_slider = widgets.IntSlider(value=3, min=1, max=15, step=1, description=r'$\\sigma$')\n",
    "button = widgets.Button(description='Apply Colorization')\n",
    "\n",
    "\n",
    "def colorization_callback(img):\n",
    "    mode = mode_dictionary[mode_dropdown.value]\n",
    "    features = orientation_features(img, sigma=sigma_slider.value)\n",
    "    return colorize_features(features[0], features[2], img, mode=mode)\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "image_list = [wave_ramp, dendrochronology, fingerprint]\n",
    "title = [\"wave_ramp\", \"dendrochronology\", \"fingerprint\"]\n",
    "new_widgets = [mode_dropdown, sigma_slider, button]\n",
    "view = viewer(image_list, new_widgets=new_widgets, callbacks=[colorization_callback], widgets=True, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b3ca17a76e7d2ef9aa342f091bd00a4a",
     "grade": false,
     "grade_id": "cell-f282f7edfcdf4135",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Application\n",
    "\n",
    "We implement applications relying on functions implemented in the previous sections, outlining their merit in real-life applications.\n",
    "\n",
    "## Orientation selection (2 points)\n",
    "\n",
    "We develop a function that only selects areas of the image with a specific orientation.\n",
    "In particular, the algorithm should preserve pixels where\n",
    " - $E > T E_{max}$, where $E_{max}$ is the maximum energy in the image and $T\\in[0, 1]$ is a relative threshold,\n",
    " - $C > 0.5$,\n",
    " - $\\theta_{min} \\leq \\theta(x, y) \\leq \\theta_{max}$.\n",
    "\n",
    "**For 2 points**, implement the function `select_direction` taking the arguments\n",
    "* `img`: The input image\n",
    "* `sigma`: $\\sigma$ to be used in `orientation_features`\n",
    "* `T`: The relative energy threshold\n",
    "* `theta_min`: The minimum angle $\\theta_{min}$\n",
    "* `theta_max`: The maximum angle $\\theta_{max}$\n",
    "\n",
    "and returning\n",
    "\n",
    "* `output`: Output image keeping the pixels with the given features, with all other pixels set to the minimum value of the image (not necessarily 0).\n",
    "\n",
    "Use the function `orientation_features` you implemented in [Part 2.A.](#2.A.-Feature-calculation-(4-points)) to get the features needed.\n",
    "\n",
    "**Note:** We account for the periodicity of $\\theta$ as follows:\n",
    "If $\\theta_{\\mathrm{min}} \\leq \\theta_{\\mathrm{max}}$ then return the values inside the range $[\\theta_{\\mathrm{min}}, \\theta_{\\mathrm{max}}]$, otherwise return the values that are outside this range, i.e., $[-\\pi/2,\\pi/2] \\setminus (\\theta_{\\mathrm{max}}, \\theta_{\\mathrm{min}})$ (see [relative complement](https://en.wikipedia.org/wiki/Complement_(set_theory)#Relative_complement)).\n",
    "As an example, if $\\theta_{\\mathrm{min}} = \\frac{\\pi}{3}$ and $\\theta_{\\mathrm{max}} = -\\frac{\\pi}{3}$, the function should keep all orientation in the ranges $[\\frac{\\pi}{3}, \\frac{\\pi}{2}]$ and $[-\\frac{\\pi}{2}, -\\frac{\\pi}{3}]$ but discard all orientations in the range $(-\\frac{\\pi}{3}, \\frac{\\pi}{3})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c63e7e57be8bab98b399278ff0c4ff3b",
     "grade": false,
     "grade_id": "cell-7ebcdf2e46ec9843",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def select_direction(img, sigma, T, theta_min, theta_max):\n",
    "    assert -np.pi/2 <= theta_min <= np.pi/2, 'theta_min should be in [-pi/2, pi/2]'\n",
    "    assert -np.pi/2 <= theta_max <= np.pi/2, 'theta_max should be in [-pi/2, pi/2]'\n",
    "    \n",
    "    output = img.copy()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96a817472616874ee14e2931b729dc23",
     "grade": false,
     "grade_id": "cell-d4adac96d837cb9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell will evaluate your function on a test image that consists of 4 lines at the angles $0$, $\\frac{\\pi}{4}$, $-\\frac{\\pi}{4}$ and $\\frac{\\pi}{2}$. The function will be called on this test image with the ranges $[-\\frac{\\pi}{6}, \\frac{\\pi}{6}]$, $[\\frac{\\pi}{6}, \\frac{\\pi}{3}]$, $[-\\frac{\\pi}{3}, -\\frac{\\pi}{6}]$, and $[\\frac{\\pi}{3}, -\\frac{\\pi}{3}]$, which should each extract only one of the lines. Run the cell below to apply this sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89239833e7615bc8bfd3b6a2166a9f0b",
     "grade": true,
     "grade_id": "cell-80bb1e523f292dcb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create test image consisting of 4 lines at 0, pi/2, pi/4 and -pi/4\n",
    "n = 49\n",
    "r = n//2\n",
    "\n",
    "line0 = np.zeros((n, n))\n",
    "line0[r, :r-6] = 1\n",
    "line0[r, r+7:] = 1\n",
    "line0 = np.pad(line0, 1)\n",
    "\n",
    "line90 = np.rot90(line0)\n",
    "\n",
    "line45 = np.zeros((n, n))\n",
    "line45[range(n-1, r+6, -1), range(r-6)] = 1\n",
    "line45[range(r-7, -1, -1), range(r+7, n)] = 1\n",
    "line45 = np.pad(line45, 1)\n",
    "\n",
    "lineM45 = np.rot90(line45)\n",
    "\n",
    "test_img = line0 + line90 + line45 + lineM45\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(test_img)\n",
    "\n",
    "# Test the 4 lines\n",
    "lines = [line0, line45, lineM45, line90]\n",
    "ranges = [[-np.pi/6, np.pi/6], [np.pi/6, np.pi/3], [-np.pi/3, -np.pi/6], [np.pi/3, -np.pi/3]]\n",
    "names = ['horizontal', 'diagonal ascending', 'diagonal descending', 'vertical']\n",
    "check = True\n",
    "for i, ran in enumerate(ranges):\n",
    "    test_dir = select_direction(test_img, T=0.1, sigma=2, theta_min=ran[0], theta_max=ran[1])\n",
    "    if not np.allclose(test_dir, lines[i]):\n",
    "        check = False\n",
    "        print(f'WARNING!\\nOnly the {names[i]} line should be visible at theta_min={ran[0]:.3f}, theta_max={ran[1]:.3f}!\\n')\n",
    "        view = viewer([test_dir, lines[i]], title=[f'Your output for min={ran[0]:.3f}, max={ran[1]:.3f}', 'Expected output'], subplots=(1,2))\n",
    "if check:\n",
    "    print('Well done, your function passed the sanity check!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "107ab6f9a10c1051914741e69621eb83",
     "grade": false,
     "grade_id": "cell-4b31587ba3f17bae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, we apply our function to real images and play around with the different parameters by clicking on the button `Extra Widgets`.\n",
    "The images can be cycled by clicking *Next* and *Prev*.\n",
    "For some images, $T$ needs to be very small to extract any orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38bc2a7efc37b3c7ce8c72c4369b7cac",
     "grade": false,
     "grade_id": "cell-8c2eebd3aac72aa7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define Sliders and button\n",
    "min_slider, max_slider = [\n",
    "    widgets.FloatSlider(value=-np.pi/2, min=-np.pi/2, max=np.pi/2, step=0.01, description=description)\n",
    "    for description in ['$\\\\theta_\\\\mathrm{min}$', '$\\\\theta_\\\\mathrm{max}$']\n",
    "]\n",
    "T_slider = widgets.FloatSlider(value=0.5, min=0.05, max=0.95, step=0.05, description=r'$T$')\n",
    "sigma_slider = widgets.IntSlider(value=3, min=1, max=15, step=1, description=r'$\\sigma$')\n",
    "button = widgets.Button(description='Extract Orientation')\n",
    "\n",
    "\n",
    "def orientation_callback(img):\n",
    "    return select_direction(img, sigma_slider.value, T_slider.value, min_slider.value, max_slider.value)\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "image_list = [wave_ramp, dendrochronology, fingerprint]\n",
    "new_widgets = [sigma_slider, T_slider, min_slider, max_slider, button]\n",
    "view = viewer(image_list, new_widgets=new_widgets, callbacks=[orientation_callback], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fc5f6491d7484bb4d3863bc14932e0e",
     "grade": false,
     "grade_id": "cell-906043185ffbce3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Harris corner detector (2 points)\n",
    "\n",
    "The Harris index can be interpreted as the probability of having a corner.\n",
    "Thus, we can implement a basic corner detector by extracting the local maxima of the Harris index image.\n",
    "\n",
    "**For 1 point**, complete `detect_corners` taking as arguments\n",
    " * `img`: The input image\n",
    " * `region_size`: At most one peak is supposed to be detected in a (region_size x region_size) region\n",
    " * `threshold`: a relative threshold in the range $[0, 1]$, where only local maxima that are above $T$ times the image maximum are kept. \n",
    "\n",
    "and returning\n",
    " * `output`: Coordinated of the local maxima.\n",
    "\n",
    "Get the Harris index using `orientation_features` with `sigma=1`.\n",
    "To extract the local maxima, use [`skimage.feature.peak_local_max`](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.peak_local_max).\n",
    "`min_distance` in `peak_local_max` is related to `region_size` by `region_size = 2 * min_distance + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "48752521020a9e659b628d42884a548d",
     "grade": false,
     "grade_id": "cell-dec1d2e15105646e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "\n",
    "def detect_corners(img, region_size, threshold):\n",
    "    # This is a dummy initialization; the output should be an array of shape (detected_points, 2)\n",
    "    output = img.copy()\n",
    "    # YOUR CODE HERE\n",
    "    return output\n",
    "\n",
    "\n",
    "def visualize_corners(img, corners):\n",
    "    peak_mask = np.zeros_like(img)\n",
    "    peak_mask[tuple(corners.T)] = True\n",
    "    corners = skimage.morphology.dilation(peak_mask)\n",
    "    output = np.tile(img[..., None], (1, 1, 3))\n",
    "    output[corners > 0] = [1, 0, 0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fccf619a89f7d33c0e594d7458fff9d",
     "grade": false,
     "grade_id": "cell-9f8b33abefebf26c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to test your `detect_corners` function on a test image that contains 12 corners. Your function should be able to detect them all correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b59becd46d718380b4af6ac97f9f6a7",
     "grade": true,
     "grade_id": "cell-1bd1d44c7627469a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create test image\n",
    "n = 51\n",
    "r = n // 2\n",
    "test_img = np.zeros((n, n))\n",
    "test_img[r - 15:r + 16,r - 5:r + 6] = 1\n",
    "test_img[r - 5:r + 6,r - 15:r + 16] = 1\n",
    "\n",
    "detected_corners = detect_corners(test_img, 3, 0.5)\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer(visualize_corners(test_img, detected_corners))\n",
    "# Check that the number of detected corners is 12\n",
    "if len(detected_corners) != 12:\n",
    "    print(f'Warning: Detected {len(detected_corners)} corners instead of 12.')\n",
    "else:\n",
    "    print(\"Correctly detected 12 corners in the image. Verify the correct location by looking at the picture.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21795702b6a0b018541b4329e4d95d73",
     "grade": false,
     "grade_id": "cell-aba4cb8d5414a02a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the cell below, we create an extra widget to experiment with `region_size` and `threshold`.\n",
    "We use this information to answer the upcoming MCQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e5432cab6884a4f884f8463b5636b7c",
     "grade": false,
     "grade_id": "cell-8d18812943a18e17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "T_slider = widgets.FloatSlider(value=0.5, min=0.05, max=0.95, step=0.05, description=r'$T$')\n",
    "L_slider = widgets.IntSlider(value=3, min=1, max=31, step=2, description=r'$L$')\n",
    "button = widgets.Button(description='Detect Corners')\n",
    "\n",
    "\n",
    "def corner_callback(img):\n",
    "    return visualize_corners(img, detect_corners(img, L_slider.value, T_slider.value))\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "view = viewer([harris_corner, corner], new_widgets=[T_slider, L_slider, button], \n",
    "              callbacks=[corner_callback], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6a213296b410225e2d898848b7fd8d4",
     "grade": false,
     "grade_id": "cell-6d0540daa8777c33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple Choice Question\n",
    "\n",
    "* Q1: In general, a higher $L$ leads to\n",
    "    1. more corners, because a higher area is covered,\n",
    "    2. less corners, because values need to be a local maximum in a larger area,\n",
    "    3. less corners, because fewer areas of the image are observed, or\n",
    "    4. more corners, because more areas of the image are observed.\n",
    "\n",
    "\n",
    "* Q2: In general, selecting a higher $T$ means that a corner has to be ... to be detected.\n",
    "    1. sharper, so that it's more defined,\n",
    "    2. rounder, so that it's less defined, or\n",
    "    3. more diffuse, so that it covers more area.\n",
    " \n",
    "In the next cell, modify the variables `answer_one` and `answer_two` to reflect your answers. The following two cells are for you to check that your answer is in the valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e9f562dafb2220fa9d9ffc48e0ff54f",
     "grade": false,
     "grade_id": "cell-a511f33975192a71",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_one = None\n",
    "answer_two = None\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "76c7553afe15fd74261133ee809c1575",
     "grade": true,
     "grade_id": "cell-4fcc259ea4c4af80",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if not answer_one in [1, 2, 3, 4]:\n",
    "    print('WARNING!\\nChoose one of 1, 2, 3 or 4.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37385e435dddf1e1cfe5d048c675bdfb",
     "grade": true,
     "grade_id": "cell-50f489b5954342d8",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if not answer_two in [1, 2, 3]:\n",
    "    print('WARNING!\\nChoose one of 1, 2 or 3.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "edc9346029c38afe50d5b287f9700c5d",
     "grade": false,
     "grade_id": "cell-574705ebfa0c74ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## *Advanced:* Isotropic filtering in the Fourier space (1 point)\n",
    "\n",
    "In the first exercise, we used the Sobel filter to compute the gradient for the structure tensor.\n",
    "We illustrate the *anisotropy* of the Sobel filter using an image that contains the same number of pixels for every possible orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dbce12f38359935a38bfabbf0d6e6c04",
     "grade": false,
     "grade_id": "cell-c57f53ab2b89c278",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_test_img(ny, nx):\n",
    "    # Minimum and maximum radial frequencies\n",
    "    fmin = 0.02\n",
    "    fmax = 8 * fmin\n",
    "    # Center\n",
    "    hx = nx / 2\n",
    "    hy = ny / 2;\n",
    "    n = min(nx, ny)\n",
    "    def structure_func(j, i):\n",
    "        r = np.sqrt((i - hx)**2 + (j - hy)**2)\n",
    "        u = 1.0 / (1.0 + np.exp((r - n * 0.45) / 2.0))\n",
    "        f = fmin + r * (fmax - fmin) / n\n",
    "        v = np.sin(np.pi * 2 * f * r)\n",
    "        return (1.0 + v * u) * 128\n",
    "    return np.fromfunction(structure_func, shape=(ny, nx))\n",
    "\n",
    "\n",
    "test_img = create_test_img(2048, 2048)\n",
    "plt.close('all')\n",
    "view = viewer(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a512a290439f534228df02b01835d2b1",
     "grade": false,
     "grade_id": "cell-f02ea3b5e03dccc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plotting the distribution of the orientations (of a circular cut-out) of this image should result in a flat line.\n",
    "However, the cell below illustrates that this is not the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "446d8b788bda49a7af713478dc04206c",
     "grade": false,
     "grade_id": "cell-575e17460ab73c7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sigma = 5\n",
    "orientation = orientation_features(test_img, sigma=sigma)[0]\n",
    "\n",
    "def plot_orientation_histogram(orientation):\n",
    "    mask = np.fromfunction(\n",
    "        lambda i, j: np.sqrt((i-orientation.shape[0]//2)**2 + (j-orientation.shape[1]//2)**2), \n",
    "        shape=orientation.shape\n",
    "    ) <  np.min(orientation.shape)//2 - np.min(orientation.shape)//20\n",
    "    \n",
    "    hist, edg = np.histogram(orientation[mask], bins=1000)\n",
    "    cent = (edg[0:-1] + edg[1:]) / 2\n",
    "    orientation[~mask] = np.nan  # Only display relevant regions\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax[0].imshow(orientation)\n",
    "    ax[0].set_title('Orientation')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].set_title('Orientation distribution')\n",
    "    ax[1].set_xlabel('Angle in radians')\n",
    "    ax[1].set_ylabel('Number of pixels')\n",
    "    ax[1].plot(cent, hist)\n",
    "    ax[1].grid(); \n",
    "    ax[1].set_xticks(ticks=[-np.pi/2,-np.pi/4,0,np.pi/4,np.pi/2], labels=[r'$-\\pi/2$',r'$-\\pi/4$',r'$0$',r'$\\pi/4$',r'$\\pi/2$'])\n",
    "    plt.show()\n",
    "\n",
    "plot_orientation_histogram(orientation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2cc04d911a527812b1993f9fc5e682eb",
     "grade": false,
     "grade_id": "cell-3c6215e6afb796fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The histogram reveals that some orientations are preferred over others.\n",
    "Specifically, ignoring the peaks at $0$, $\\pm\\frac{\\pi}{4}$ and $\\pm\\frac{\\pi}{2}$ (an artifact of having a limited number of pixels), there are more pixels with an orientation close to $0$ or $\\pm\\frac{\\pi}{2}$ and less pixels close to $\\pm\\frac{\\pi}{4}$. \n",
    "This is because the Sobel filters\n",
    "\n",
    "$$h_x = \n",
    "\\begin{bmatrix} \n",
    "    1 & 0 & -1 \\\\\n",
    "    2 & 0 & -2 \\\\ \n",
    "    1 & 0 & -1 \n",
    "\\end{bmatrix}\n",
    ",\\;\\;\\;\\;\n",
    "h_y = \n",
    "\\begin{bmatrix} \n",
    "    1 & 2 & 1 \\\\\n",
    "    0 & 0 & 0 \\\\ \n",
    "    -1 & -2 & -1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "are anisotropic, favoring grid-aligned edges.\n",
    "To have a non-biased orientation detector, we re-implement `structure_tensor` using an isotropic gradient filter.\n",
    "Several choices of these filters exist; in this exercise, we exploit the Fourier property\n",
    "\n",
    "$$\\frac{\\partial f(x,y)}{\\partial x} \\xrightarrow{\\mathcal{F}} j\\omega_x\\operatorname{F}(\\omega_x, \\omega_y), \\;\\;\\; \n",
    "\\frac{\\partial f(x,y)}{\\partial y} \\xrightarrow{\\mathcal{F}} j\\omega_y\\operatorname{F}(\\omega_x, \\omega_y)\\,.$$\n",
    "\n",
    "Thus, to implement an isotropic gradient filter, we need to Fourier transform our image, multiply by $j\\omega_x$ and $j\\omega_y$ (for the two spatial directions respectively), and invert the Fourier transform.\n",
    "\n",
    "**For 1 point**, implement `structure_tensor_improved` utilizing the frequency-domain filters $j\\omega_x$ and $j\\omega_y$.\n",
    "Use [`np.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) to generate the frequency vectors containing equidistant points.\n",
    "The utility functions `cfft2` and `icfft2` implement the Fourier transform with shifting, such that the DC component is in the center of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c286ce16507b2d6fcaeec97988e83651",
     "grade": false,
     "grade_id": "cell-ffc5cf790a58c210",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cfft2(img):\n",
    "    return np.fft.fftshift(np.fft.fft2(img))\n",
    "\n",
    "\n",
    "def icfft2(img):\n",
    "    return np.fft.ifft2(np.fft.ifftshift(img)).real\n",
    "    \n",
    "\n",
    "def structure_tensor_improved(img, sigma):\n",
    "    # Compute the structure tensor using the frequency domain filters\n",
    "    # Only the gradient computation should change compared to the previous implementation\n",
    "    # You can reuse parts of the previous implementation\n",
    "    Jxx, Jxy, Jyy = [np.empty_like(img) for _ in range(3)]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return Jxx, Jxy, Jyy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ec4c7a3a1ffac94bd09a92ba4e50e6",
     "grade": false,
     "grade_id": "cell-57e074d92e1518c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We plot the results, comparing them to the previous version using the Sobel gradient filters.\n",
    "We see that the Fourier version is flat (with the exception of a few sharp spikes), whereas the Sobel version looks like a sinusoidal wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54675f3e083f77ba7e7ead727bddad5f",
     "grade": true,
     "grade_id": "cell-ab597977ff6f8830",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "orientation_improved = orientation_features(test_img, sigma=sigma, structure_tensor=structure_tensor_improved)[0]\n",
    "plot_orientation_histogram(orientation_improved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec777e95c5ae30ae937a95ceafbc09ba",
     "grade": false,
     "grade_id": "footer",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "🎉 Congratulations on finishing the Orientation lab!! 🎉\n",
    "\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to Moodle, **in a zip file with the other notebook of this lab.**\n",
    "\n",
    "* Keep the name of the notebook as: *2_orientation.ipynb*,\n",
    "* Name the `zip` file: *orientation_lab.zip*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
